
@inproceedings{liu_isolation_2008,
	address = {Pisa, Italy},
	title = {Isolation {Forest}},
	isbn = {978-0-7695-3502-9},
	url = {http://ieeexplore.ieee.org/document/4781136/},
	doi = {10.1109/ICDM.2008.17},
	abstract = {Most existing model-based approaches to anomaly detection construct a proﬁle of normal instances, then identify instances that do not conform to the normal proﬁle as anomalies. This paper proposes a fundamentally different model-based method that explicitly isolates anomalies instead of proﬁles normal points. To our best knowledge, the concept of isolation has not been explored in current literature. The use of isolation enables the proposed method, iForest, to exploit sub-sampling to an extent that is not feasible in existing methods, creating an algorithm which has a linear time complexity with a low constant and a low memory requirement. Our empirical evaluation shows that iForest performs favourably to ORCA, a near-linear time complexity distance-based method, LOF and Random Forests in terms of AUC and processing time, and especially in large data sets. iForest also works well in high dimensional problems which have a large number of irrelevant attributes, and in situations where training set does not contain any anomalies.},
	language = {en},
	urldate = {2024-12-05},
	booktitle = {2008 {Eighth} {IEEE} {International} {Conference} on {Data} {Mining}},
	publisher = {IEEE},
	author = {Liu, Fei Tony and Ting, Kai Ming and Zhou, Zhi-Hua},
	month = dec,
	year = {2008},
	pages = {413--422},
	file = {Liu et al. - 2008 - Isolation Forest.pdf:/Users/yuanxiong/Zotero/storage/VGN3WSDI/Liu et al. - 2008 - Isolation Forest.pdf:application/pdf},
}

@article{xu_deep_2023,
	title = {Deep {Isolation} {Forest} for {Anomaly} {Detection}},
	volume = {35},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1041-4347, 1558-2191, 2326-3865},
	url = {https://ieeexplore.ieee.org/document/10108034/},
	doi = {10.1109/TKDE.2023.3270293},
	abstract = {Isolation forest (iForest) has been emerging as arguably the most popular anomaly detector in recent years due to its general effectiveness across different benchmarks and strong scalability. Nevertheless, its linear axis-parallel isolation method often leads to (i) failure in detecting hard anomalies that are difficult to isolate in high-dimensional/non-linear-separable data space, and (ii) notorious algorithmic bias that assigns unexpectedly lower anomaly scores to artefact regions. These issues contribute to high false negative errors. Several iForest extensions are introduced, but they essentially still employ shallow, linear data partition, restricting their power in isolating true anomalies. Therefore, this paper proposes deep isolation forest. We introduce a new representation scheme that utilises casually initialised neural networks to map original data into random representation ensembles, where random axis-parallel cuts are subsequently applied to perform the data partition. This representation scheme facilitates high freedom of the partition in the original data space (equivalent to non-linear partition on subspaces of varying sizes), encouraging a unique synergy between random representations and random partition-based isolation. Extensive experiments show that our model achieves significant improvement over state-of-the-art isolation-based methods and deep detectors on tabular, graph and time series datasets; our model also inherits desired scalability from iForest.},
	language = {en},
	number = {12},
	urldate = {2024-12-05},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Xu, Hongzuo and Pang, Guansong and Wang, Yijie and Wang, Yongjun},
	month = dec,
	year = {2023},
	pages = {12591--12604},
	file = {Xu et al. - 2023 - Deep Isolation Forest for Anomaly Detection.pdf:/Users/yuanxiong/Zotero/storage/CAIJC42Y/Xu et al. - 2023 - Deep Isolation Forest for Anomaly Detection.pdf:application/pdf},
}

@article{sohil_introduction_2022,
	title = {An introduction to statistical learning with applications in {R}: by {Gareth} {James}, {Daniela} {Witten}, {Trevor} {Hastie}, and {Robert} {Tibshirani}, {New} {York}, {Springer} {Science} and {Business} {Media}, 2013, \$41.98, {eISBN}: 978-1-4614-7137-7},
	volume = {6},
	issn = {2475-4269, 2475-4277},
	shorttitle = {An introduction to statistical learning with applications in {R}},
	url = {https://www.tandfonline.com/doi/full/10.1080/24754269.2021.1980261},
	doi = {10.1080/24754269.2021.1980261},
	language = {en},
	number = {1},
	urldate = {2024-12-05},
	journal = {Statistical Theory and Related Fields},
	author = {Sohil, Fariha and Sohali, Muhammad Umair and Shabbir, Javid},
	month = jan,
	year = {2022},
	pages = {87--87},
	file = {Sohil et al. - 2022 - An introduction to statistical learning with appli.pdf:/Users/yuanxiong/Zotero/storage/V7YI44MT/Sohil et al. - 2022 - An introduction to statistical learning with appli.pdf:application/pdf},
}

@inproceedings{sakurada_anomaly_2014,
	address = {Gold Coast Australia QLD Australia},
	title = {Anomaly {Detection} {Using} {Autoencoders} with {Nonlinear} {Dimensionality} {Reduction}},
	isbn = {978-1-4503-3159-3},
	url = {https://dl.acm.org/doi/10.1145/2689746.2689747},
	doi = {10.1145/2689746.2689747},
	abstract = {This paper proposes to use autoencoders with nonlinear dimensionality reduction in the anomaly detection task. The authors apply dimensionality reduction by using an autoencoder onto both artiﬁcial data and real data, and compare it with linear PCA and kernel PCA to clarify its property. The artiﬁcial data is generated from Lorenz system, and the real data is the spacecrafts’ telemetry data. This paper demonstrates that autoencoders are able to detect subtle anomalies which linear PCA fails. Also, autoencoders can increase their accuracy by extending them to denoising autoenconders. Moreover, autoencoders can be useful as nonlinear techniques without complex computation as kernel PCA requires. Finaly, the authors examine the learned features in the hidden layer of autoencoders, and present that autoencoders learn the normal state properly and activate diﬀerently with anomalous input.},
	language = {en},
	urldate = {2025-01-16},
	booktitle = {Proceedings of the {MLSDA} 2014 2nd {Workshop} on {Machine} {Learning} for {Sensory} {Data} {Analysis}},
	publisher = {ACM},
	author = {Sakurada, Mayu and Yairi, Takehisa},
	month = dec,
	year = {2014},
	pages = {4--11},
	file = {Sakurada and Yairi - 2014 - Anomaly Detection Using Autoencoders with Nonlinea.pdf:/Users/yuanxiong/Zotero/storage/YDAF9SHZ/Sakurada and Yairi - 2014 - Anomaly Detection Using Autoencoders with Nonlinea.pdf:application/pdf},
}